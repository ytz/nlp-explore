{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8ec3c98e-8e01-4a5d-a9bd-b0088b60cb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import io\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5de5307b-be94-490a-83f1-025d64e0a2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.yml', \"r\") as stream:\n",
    "    try:\n",
    "        cf = yaml.safe_load(stream)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)\n",
    "\n",
    "\n",
    "auth = tweepy.OAuth1UserHandler(\n",
    "    cf['twitter_key'], \n",
    "    cf['twitter_secret'], \n",
    "    cf['twitter_access_key'], \n",
    "    cf['twitter_access_secret']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "99462a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_list = [1643966166]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f5a1d3d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/Users/ytz/Documents/side-project/nlp-explore/notebook/twitter.ipynb Cell 4'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ytz/Documents/side-project/nlp-explore/notebook/twitter.ipynb#ch0000014?line=0'>1</a>\u001b[0m json\u001b[39m.\u001b[39;49mloads(\u001b[39m'\u001b[39;49m\u001b[39mlast_tweet.json\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/nlp-explore/lib/python3.10/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[39m=\u001b[39m s\u001b[39m.\u001b[39mdecode(detect_encoding(s), \u001b[39m'\u001b[39m\u001b[39msurrogatepass\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m parse_float \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_pairs_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_decoder\u001b[39m.\u001b[39;49mdecode(s)\n\u001b[1;32m    347\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/nlp-explore/lib/python3.10/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecode\u001b[39m(\u001b[39mself\u001b[39m, s, _w\u001b[39m=\u001b[39mWHITESPACE\u001b[39m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m     \u001b[39m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[39m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraw_decode(s, idx\u001b[39m=\u001b[39;49m_w(s, \u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mend())\n\u001b[1;32m    338\u001b[0m     end \u001b[39m=\u001b[39m _w(s, end)\u001b[39m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[39mif\u001b[39;00m end \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(s):\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/nlp-explore/lib/python3.10/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m     obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscan_once(s, idx)\n\u001b[1;32m    354\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[39mraise\u001b[39;00m JSONDecodeError(\u001b[39m\"\u001b[39m\u001b[39mExpecting value\u001b[39m\u001b[39m\"\u001b[39m, s, err\u001b[39m.\u001b[39mvalue) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    356\u001b[0m \u001b[39mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "json.loads('last_tweet.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2cf31e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load last tweet_id dict\n",
    "if os.path.isfile('last_tweet.json') and os.access('last_tweet.json', os.R_OK):\n",
    "    with open('last_tweet.json', 'r') as jsonfile:\n",
    "        last_tweet_dict = json.load(jsonfile)\n",
    "else:\n",
    "    last_tweet_dict = defaultdict(lambda: None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "65095402",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = tweepy.Client(bearer_token=cf['twitter_bearer'])\n",
    "\n",
    "def extract_tweet(id, since_id=None, pagination_token=None, first=True):\n",
    "    res = client.get_users_tweets(id, since_id=since_id, tweet_fields=[\n",
    "    'created_at', \n",
    "    'author_id', \n",
    "    'conversation_id', \n",
    "    'in_reply_to_user_id',\n",
    "    'referenced_tweets',\n",
    "    'attachments'],\n",
    "    max_results=100,\n",
    "    pagination_token=pagination_token)\n",
    "\n",
    "    # Quit if no more data\n",
    "    if res.data is None:\n",
    "        return\n",
    "\n",
    "    # Update last tweet id\n",
    "    if first:\n",
    "        print(id, res.data[0].id)\n",
    "        last_tweet_dict[id] = res.data[0].id\n",
    "\n",
    "    for curr in res.data:\n",
    "        with open(f'tweet_json/{curr.data[\"id\"]}.json', 'w') as json_file:\n",
    "            json.dump(curr.data, json_file)\n",
    "    \n",
    "    if 'next_token' in res.meta:\n",
    "        extract_tweet(id, pagination_token=res.meta['next_token'], first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f28bd6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for user_id in user_list:\n",
    "    extract_tweet(user_id, since_id=last_tweet_dict[str(user_id)])\n",
    "\n",
    "with open('last_tweet.json', 'w') as json_file:\n",
    "    json.dump(last_tweet_dict, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc3af7e9-3ebf-47be-a86b-c9dc8c06b106",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# @@bennstancil\n",
    "res = client.get_users_tweets(id=1643966166, since_id=None, tweet_fields=[\n",
    "    'created_at', \n",
    "    'author_id', \n",
    "    'conversation_id', \n",
    "    'in_reply_to_user_id',\n",
    "    'referenced_tweets',\n",
    "    'attachments'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ee0336d-a4cd-483b-b4e7-a6c1274b57b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(data=[<Tweet id=1542942959913603072 text=\"@alexkyllo @matsonj @dataklump i think it goes well beyond this. it's not a semantic model of the *data* and their relationships; it's a operational model of the metrics and how they move one another. it's the company's supply and demand curves - an abstract description of how it moves.\">, <Tweet id=1542938639486812160 text=\"@Cavorax @ArynnPost @leoebfolsom wait, that distinction doesn't make sense to me...what do you mean?\">, <Tweet id=1542938367901536259 text='@alexkyllo @matsonj @dataklump a rant for another day, but i think it means that analysts do something different than just dashboards and decks, and instead build something like \"operational models,\" which is an obnoxious term but a very valuable thing'>, <Tweet id=1542937549995446275 text='@gwenwindflower does this end up meaning we split analysts in half, and then the AE half conquers the analyst half, so we end up with analysts again, but this time everyone has appreciation for and sort of quirky love of data modeling?'>, <Tweet id=1542911484564578307 text=\"@josh_wills i'm a week early https://t.co/P5E4FTeaxG\">, <Tweet id=1542911269803540480 text=\"it's friday, let's fight\\n\\nhttps://t.co/1ECFtX2Idr\">, <Tweet id=1540714599632306176 text='@sayno2gods @lloydtabb jOe MaNcHiN aNd KyRsTeN sInEmA'>, <Tweet id=1540713121525878787 text=\"@n8agrin @lloydtabb exactly; that's the thing I want someone to explain. They say vote, but also explicitly take these options off the table. So they're not gonna do what @lloydtabb is saying...even if they win the elections, what *are* they doing to?\\n https://t.co/qO411gcmHg\">, <Tweet id=1540688338893516804 text=\"So after I vote, and Democrats keep the presidency, and expand their House majority, and have 55 seats in the Senate ... what's the plan then? How does this get better? \\n\\nIn this absurd, best case scenario, what exactly are Democrats going to do that they couldn't do now?\">, <Tweet id=1540366706085855232 text=\"it's friday, and it's a disaster\\n\\nhttps://t.co/3puOLtu2ZB\">], includes={}, errors=[], meta={'result_count': 10, 'newest_id': '1542942959913603072', 'oldest_id': '1540366706085855232', 'next_token': '7140dibdnow9c7btw42285wpsqukgeol4uyvj8ow1zx2q'})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21343c4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"@alexkyllo @matsonj @dataklump i think it goes well beyond this. it's not a semantic model of the *data* and their relationships; it's a operational model of the metrics and how they move one another. it's the company's supply and demand curves - an abstract description of how it moves.\",\n",
       " 'author_id': '1643966166',\n",
       " 'id': '1542942959913603072',\n",
       " 'conversation_id': '1542911269803540480',\n",
       " 'created_at': '2022-07-01T18:47:22.000Z',\n",
       " 'in_reply_to_user_id': '1406821746',\n",
       " 'referenced_tweets': [{'type': 'replied_to', 'id': '1542939515446210561'}]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.data[0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03f65d46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(data=[<Tweet id=1537857493224697856 text=\"@juansequeda @HonestNoBSData i didn't, i avoided it and every booth within 50 feet of it\">, <Tweet id=1537857146011803648 text='@gwenwindflower definitely read that as https://t.co/NIBJPHdEry'>, <Tweet id=1537856769027846144 text=\"@JPedro_Monteiro @decentriq no, different thing. I don't know exactly what the company did to be honest. It was just enough to get me to realize what other companies could do.\">, <Tweet id=1537843768279199744 text=\"it's friday, let's fight snowflake about what snowflake is building\\n\\nhttps://t.co/aZ9tRcVZOU\">, <Tweet id=1536357557329084416 text='@thenanyu i hear they got a good designer tho'>, <Tweet id=1536073886701330436 text='@Patrick_Rankin better that than the scary magic the gathering teenagers at joe muggs that you had to walk past to get to the people playing pokemon'>, <Tweet id=1536073217294614530 text=\"@mullinsms They could, I suppose, but don't seem to have that much interest in it\">, <Tweet id=1536064156826230785 text=\"They have the technology to build it, and the capital to buy it. I don't know if they have the vision to imagine it.\">, <Tweet id=1536063382197002240 text='Today, they don’t have anywhere to go - not for anything particularly good.\\n\\nThat’s Google’s opportunity. Design a cohesive deck of integrated cards. Take inspiration from what’s serving the data community, and make it accessible, seamless, and easy to buy.'>, <Tweet id=1536063062138097667 text=\"Having to manage open source software or buy from ten vendors is enough to make these folks look elsewhere (not because they're bad at their jobs; because they're good at their lives, and have better hobbies than writing about data tools on substack).\">], includes={}, errors=[], meta={'result_count': 10, 'newest_id': '1537857493224697856', 'oldest_id': '1536063062138097667', 'previous_token': '77qpymm88g5h9vqklurd9urpkn6e8x08bo6vvqkkkbbxy', 'next_token': '7140dibdnow9c7btw421td28eduf05vzbdeir1j4cc65z'})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_users_tweets(id=1643966166, pagination_token='7140dibdnow9c7btw421tf9cwn04vtmtaxevjgrmziu5s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad3fecb2-00af-483a-99fd-f3e1592f2350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweepy.tweet.Tweet"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(res.data[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 ('nlp-explore')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "88167ad7c88de4d823b10dc4df4887ee02c1f4ce02650f2f4997a21f4616c7eb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
